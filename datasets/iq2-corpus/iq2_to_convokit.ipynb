{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IQ2 Dataset to Convokit format conversion script\n",
    "Marianne Aubin Le Quere and Lucas Van Bramer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, change directory to find convokit location\n",
    "# import required modules and set up environment\n",
    "import os\n",
    "\n",
    "# replace file path below with your own local convokit\n",
    "os.chdir('./Cornell-Conversational-Analysis-Toolkit')\n",
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, Speaker, Utterance\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates all of the users who are listed in the metadata of a specific debate's \"speakers\" field\n",
    "# args: debate_id is a key used by the iq2 dataset, e.g. \"PerformanceEnhancingDrugs-011508\"\n",
    "# returns: a dictionary in which keys are speakers' full names and values are dictionaries containing metadata\n",
    "def generate_users(debate_id):\n",
    "    debate = iq2[debate_id]\n",
    "    users = {}\n",
    "    for stance in [\"for\", \"against\"]:\n",
    "        for speaker in debate[\"speakers\"][stance]:\n",
    "            meta = {}\n",
    "            meta[\"bio\"] = speaker[\"bio\"]\n",
    "            meta[\"bio_short\"] = speaker[\"bio_short\"]\n",
    "            users[speaker[\"name\"]] = meta\n",
    "    mod = debate[\"speakers\"][\"moderator\"]\n",
    "    modmeta = {}\n",
    "    modmeta[\"bio\"] = mod[\"bio\"]\n",
    "    modmeta[\"bio_short\"] = mod[\"bio_short\"]\n",
    "    users[mod[\"name\"]] = modmeta\n",
    "    users[\"audience\"] = {\"bio\": None, \"bio_short\": None}\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates all of the users in the iq2 dataset \n",
    "# args: dataset is the python object containing the iq2 dataset parsed from json\n",
    "# returns: a dictionary in which keys are speakers' full names and values are dictionaries containing metadata\n",
    "def generate_all_users_convokit(dataset):\n",
    "    all_users = {}\n",
    "    for debate_id in dataset.keys():\n",
    "        res = generate_users(debate_id)\n",
    "        \n",
    "        for fullname, usermeta in res.items():\n",
    "            all_users[fullname] = usermeta\n",
    "    print(str(len(all_users.keys())) + \" users generated.\")\n",
    "    convokit_all_users = {k: Speaker(id = k, meta = v) for k,v in all_users.items()}\n",
    "    return convokit_all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates all of the convokit utterances from the iq2 dataset \n",
    "# args: dataset is the python object containing the iq2 dataset parsed from json\n",
    "# precondition: corpus_speakers must be populated in the jupyter environment because it is called from and modified here\n",
    "# returns: convokit corpus representation of iq2 dataset\n",
    "def generate_utterance_corpus_from_dataset(dataset, v):\n",
    "    utt_id = 0\n",
    "    utterance_corpus = {}\n",
    "    for conversation_id in dataset.keys():\n",
    "        conversation = dataset[conversation_id]\n",
    "        \n",
    "        # set root of the conversation to the first utterance id in the conversation\n",
    "        convo_root = utt_id\n",
    "        for turn in conversation[\"transcript\"]:\n",
    "            utterance = {}\n",
    "            utterance[\"id\"] = str(utt_id)\n",
    "            utterance[\"root\"] = str(convo_root)\n",
    "            utterance[\"timestamp\"] = None\n",
    "            \n",
    "            paragraphbreaks = []\n",
    "            cumulen = 0\n",
    "            for paragraph in turn['paragraphs'][:-1]:\n",
    "                cumulen += len(paragraph) + 1\n",
    "                paragraphbreaks.append(cumulen)\n",
    "                \n",
    "            meta = {\n",
    "                    \"nontext\": turn[\"nontext\"], \n",
    "                    \"segment\": turn[\"segment\"],\n",
    "                    \"paragraphbreaks\": paragraphbreaks,\n",
    "                    \"speakertype\": turn[\"speakertype\"]\n",
    "                   } \n",
    "            utterance[\"meta\"] = meta\n",
    "            \n",
    "            if convo_root == utt_id:\n",
    "                utterance[\"meta\"][\"debateid\"] = conversation_id\n",
    "            # sets replied-to utterance to always be the last utterance\n",
    "            utterance[\"reply_to\"] = utt_id - 1 if convo_root != utt_id else None\n",
    "            \n",
    "            # text is originally stored as a list of strings; this concatenates them into one string\n",
    "            fulltext = \" \".join(turn[\"paragraphs\"])\n",
    "            utterance[\"text\"] = fulltext\n",
    "            \n",
    "            # \"unknown\" speakers are generally the audience\n",
    "            utterance[\"user\"] = turn[\"speaker\"] if turn[\"speakertype\"] != \"unknown\" else \"audience\"\n",
    "            \n",
    "            # in the case that a speaker in the text is not a speaker contained in the debate\n",
    "            # metadata, adds a speaker with the same schema but no metadata to the corpus users\n",
    "            if turn[\"speaker\"] not in corpus_speakers:\n",
    "                meta = {}\n",
    "                meta[\"bio\"] = None\n",
    "                meta[\"bio_short\"] = None\n",
    "                corpus_speakers[turn[\"speaker\"]] = Speaker(id=turn[\"speaker\"], meta=meta)\n",
    "                \n",
    "            # adds convokit utterance to corpus object\n",
    "            utterance_corpus[utterance[\"id\"]] = \\\n",
    "                Utterance(utterance[\"id\"], \n",
    "                          corpus_speakers[utterance[\"user\"]],\n",
    "                          utterance[\"root\"],\n",
    "                          utterance[\"reply_to\"],\n",
    "                          utterance[\"timestamp\"],\n",
    "                          utterance[\"text\"],\n",
    "                          meta=utterance[\"meta\"]\n",
    "                         )\n",
    "            # increments utterance id\n",
    "            utt_id += 1\n",
    "            \n",
    "    # converts utterance dictionary into convokit format \n",
    "    corpus = Corpus(utterances=[utt for _, utt in utterance_corpus.items()], version=v)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 debates loaded.\n"
     ]
    }
   ],
   "source": [
    "# replace open location with wherever the dataset is\n",
    "file = open('./iq2_data_release.json')\n",
    "iq2 = json.load(file)\n",
    "print(str(len(iq2.keys())) + \" debates loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470 users generated.\n"
     ]
    }
   ],
   "source": [
    "corpus_speakers = generate_all_users_convokit(iq2)\n",
    "iq2_corpus = generate_utterance_corpus_from_dataset(iq2, 1)\n",
    "iq2_corpus.meta[\"name\"] = \"IQ2 Debate Corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function determines, given a conversation, which is the winner\n",
    "\n",
    "def determine_winner(conversation):\n",
    "    results = conversation.meta[\"results\"]\n",
    "    fordelta = results[\"post\"][\"for\"] - results[\"pre\"][\"for\"]\n",
    "    againstdelta = results[\"post\"][\"against\"] - results[\"pre\"][\"against\"]\n",
    "    if(fordelta > againstdelta):\n",
    "        return \"for\"\n",
    "    elif(againstdelta > fordelta):\n",
    "        return \"against\"\n",
    "    else:\n",
    "        return \"tie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates conversation metadata based on each debate and updates the corpus conversation instances\n",
    "for conv_id in iq2_corpus.get_conversation_ids():\n",
    "    conv = iq2_corpus.get_conversation(conv_id)\n",
    "    first_utt = iq2_corpus.get_utterance(conv.get_utterance_ids()[0])\n",
    "    debate = iq2[first_utt.meta[\"debateid\"]]\n",
    "    debate_meta = {}\n",
    "    debate_meta[\"summary\"] = debate[\"summary\"]\n",
    "    debate_meta[\"title\"] = debate[\"title\"]\n",
    "    debate_meta[\"date\"] = debate[\"date\"]\n",
    "    debate_meta[\"url\"] = debate[\"url\"]\n",
    "    debate_meta[\"results\"] = debate[\"results\"]\n",
    "    debate_meta[\"originalid\"] = first_utt.meta[\"debateid\"]\n",
    "    del first_utt.meta[\"debateid\"]\n",
    "    conv.meta = debate_meta\n",
    "    conv.meta[\"winner\"] = determine_winner(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucas/Cornell-Conversational-Analysis-Toolkit\n",
      "Number of Speakers: 471\n",
      "Number of Utterances: 26562\n",
      "Number of Conversations: 108\n"
     ]
    }
   ],
   "source": [
    "# prints summary stats and dumps the corpus to file\n",
    "!pwd\n",
    "iq2_corpus.print_summary_stats()\n",
    "iq2_corpus.dump(\"iq2_corpus\", base_path='./datasets/iq2_corpus/' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq2 = convokit.Corpus(filename='datasets/iq2_corpus/iq2_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of for winners is 52\n",
      "num of against winners is 53\n",
      "num of ties is 3\n"
     ]
    }
   ],
   "source": [
    "num_for, num_against, num_tie = 0,0,0\n",
    "\n",
    "for conv_id in iq2.conversations:\n",
    "    conv = iq2.get_conversation(conv_id)\n",
    "    result = conv.meta['winner']\n",
    "    if result == 'for':\n",
    "        num_for = num_for + 1\n",
    "    elif result == 'against':\n",
    "        num_against = num_against + 1\n",
    "    else:\n",
    "        num_tie = num_tie + 1\n",
    "        \n",
    "print(\"num of for winners is \" + str(num_for))\n",
    "print(\"num of against winners is \" + str(num_against))\n",
    "print(\"num of ties is \" + str(num_tie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
