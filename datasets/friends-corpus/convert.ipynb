{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_YNRDvb3etb"
   },
   "source": [
    "# Converting the Friends dataset into ConvoKit format\n",
    "\n",
    "This notebook describes how we converted the Friends dataset (https://github.com/emorynlp/character-mining) into a Corpus with ConvoKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXk4Biep3xHH"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from convokit import Corpus, Speaker, Utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmw72j5J44E4"
   },
   "source": [
    "## The Friends Dataset\n",
    "\n",
    "The original dataset (https://github.com/emorynlp/character-mining) contains a set of 10 JSON files, each of which represents a complete transcript of 1 season of <i>Friends</i>. Since the data are available in JSON format from this GitHub repo, we download the raw data directly using the `requests` module. You will not need to download raw data files to use this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YxhlL6aNCvxr"
   },
   "source": [
    "## Generating user information\n",
    "\n",
    "Since our dataset doesn't have any existing user information, we extract speaker information from the conversation. \n",
    "Speakers are indexed by their name, which is a `<str>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mjNZT57Qv7Vd",
    "outputId": "cd19eef4-c487-4fd3-a336-705e284c0e32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "users = set()\n",
    "for i in tqdm(range(1,11)):\n",
    "  season_number = '0'+str(i) if i < 10 else '10'\n",
    "  json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_'+str(season_number)+'.json'\n",
    "  r = requests.get(json_file)\n",
    "  \n",
    "  season = json.loads(r.text)\n",
    "  episodes = season['episodes']\n",
    "  for j in range(len(episodes)):\n",
    "    episode = episodes[j]\n",
    "    scenes = episode['scenes']\n",
    "    for k in range(len(scenes)):\n",
    "      scene = scenes[k]\n",
    "      utterances = scene['utterances']\n",
    "      for l in range(len(utterances)):\n",
    "        utterance = utterances[l]\n",
    "        speaker_list = utterance['speakers']\n",
    "        for speaker in speaker_list:\n",
    "          if speaker not in users:\n",
    "            users.add(speaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJqo7WSSCua1"
   },
   "source": [
    "Sanity-checking the user data, we should see all 6 friends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "YeKBCPZqCMeH",
    "outputId": "3d8d81bf-36f4-4c7f-8424-437b32bbca56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users in the data = 700/700\n",
      "Monica Geller in users?  True\n",
      "Joey Tribbiani in users?  True\n",
      "Chandler Bing in users?  True\n",
      "Phoebe Buffay in users?  True\n",
      "Ross Geller in users?  True\n",
      "Rachel Green in users?  True\n"
     ]
    }
   ],
   "source": [
    "print(\"number of users in the data = {}/700\".format(len(users)))\n",
    "print(\"Monica Geller in users? \", \"Monica Geller\" in users)\n",
    "print(\"Joey Tribbiani in users? \", \"Joey Tribbiani\" in users)\n",
    "print(\"Chandler Bing in users? \", \"Chandler Bing\" in users)\n",
    "print(\"Phoebe Buffay in users? \", \"Phoebe Buffay\" in users)\n",
    "print(\"Ross Geller in users? \", \"Ross Geller\" in users)\n",
    "print(\"Rachel Green in users? \", \"Rachel Green\" in users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add a dummy user for transcript notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users in the data = 701/701\n"
     ]
    }
   ],
   "source": [
    "users.add(\"TRANSCRIPT_NOTE\")\n",
    "print(\"number of users in the data = {}/701\".format(len(users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Csa06wuFh8U"
   },
   "source": [
    "We then create a Speaker object for each unique character in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xs7QjJJJFg2S"
   },
   "outputs": [],
   "source": [
    "corpus_users = {k: Speaker(name=k) for k in users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cfMxU1u_GJD7",
    "outputId": "9608f357-a05d-4305-bc57-f2468f9d119e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monica Geller\n",
      "Should be an empty object:  {}\n"
     ]
    }
   ],
   "source": [
    "print(corpus_users['Monica Geller'].name)\n",
    "print('Should be an empty object: ', corpus_users['Monica Geller'].meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6tJ_9BMXFygP"
   },
   "source": [
    "## Generating Utterances\n",
    "\n",
    "We then loop through the data to generate a list of all utterances in the series. To align with the Utterance schema ConvoKit expects, we construct for each utterance:\n",
    "\n",
    "- **id:** index of the utterance\n",
    "\n",
    "- **user:** the user who authored the utterance; the speaker in our case\n",
    "\n",
    "- **root:** id of the conversation root of the utterance; the first utterance in the scene, in our case\n",
    "\n",
    "- **reply_to:** id of the utterance to which this utterance replies to; None if the utterance is not a reply.\n",
    "\n",
    "- **timestamp:** time of the utterance (None for us -- the dataset does not contain this information)\n",
    "\n",
    "- **text:** textual content of the utterance\n",
    "\n",
    "We also pull in the following metadata including:\n",
    "- **tokens** a tokenized representation of the text (handy for sentence separation)\n",
    "- **character_entities** available for some but not all utterances; `None` if unavailable. These are intended to identify who the user is speaking to and/or about.\n",
    "- **emotion** emotion labels for each token. Available for some but not all utterances; `None` if unavailable. \n",
    "- **caption**  available for some but not all utterances; `None` if unavailable. This contains the begin time, end time, and text sans punctuation. Only available for seasons 6-9.\n",
    "- **transcript_with_note**  a version of the text with an action note (e.g. \"(to Ross) Hand me the coffee\" vs. \"Hand me the coffee\"). Available for some but not all utterances; `None` if unavailable.\n",
    "- **token_with_note** a tokenized representation of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MDgFZjF6GN3O",
    "outputId": "3a963fc3-cba2-4a3a-b932-cc9526568439"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "all_utterances = {}\n",
    "\n",
    "for i in tqdm(range(1,11)):\n",
    "  season_number = '0'+str(i) if i < 10 else '10'\n",
    "  json_file = 'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_'+str(season_number)+'.json'\n",
    "  r = requests.get(json_file)\n",
    "  \n",
    "  season = json.loads(r.text)\n",
    "  episodes = season['episodes']\n",
    "  for j in range(len(episodes)):\n",
    "    episode = episodes[j]\n",
    "    scenes = episode['scenes']\n",
    "    for k in range(len(scenes)):\n",
    "      scene = scenes[k]\n",
    "      utterances = scene['utterances']\n",
    "      \n",
    "      root = utterances[0] #set the root as the first utterance in the scene for now\n",
    "      \n",
    "      prev_utt = None\n",
    "\n",
    "      for l in range(len(utterances)):\n",
    "        utterance = utterances[l]\n",
    "        \n",
    "        speaker = utterance['speakers']\n",
    "\n",
    "        # Construct the meta       \n",
    "        meta = {\n",
    "            'tokens': utterance.get('tokens'),\n",
    "            'character_entities': utterance.get('character_entities'),\n",
    "            'emotion': utterance.get('emotion'),\n",
    "            'caption': utterance.get('caption'),\n",
    "            'transcript_with_note': utterance.get('transcript_with_note'),\n",
    "            'tokens_with_note': utterance.get('tokens_with_note')\n",
    "        }\n",
    "        \n",
    "        # Create the Utterance, including meta\n",
    "        all_utterances[utterance['utterance_id']] = Utterance(\n",
    "            id=utterance['utterance_id'],\n",
    "            user=corpus_users[speaker[0]] if len(speaker) != 0 else corpus_users['TRANSCRIPT_NOTE'], # Check if people speaking or just scripts\n",
    "            root=root['utterance_id'],\n",
    "            reply_to=prev_utt,\n",
    "            timestamp=None,\n",
    "            text=utterance['transcript'],\n",
    "            meta=meta\n",
    "        )\n",
    "        \n",
    "        # Get the prev_utt for the next iteration\n",
    "        prev_utt = utterance['utterance_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pmVQJYBiI1aY",
    "outputId": "5fe98756-0ba8-4052-a288-59117417cac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This corpus has 67373/67373 utterances\n"
     ]
    }
   ],
   "source": [
    "print(\"This corpus has {}/67373 utterances\".format(len(all_utterances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "NkOm5qDdZYRQ",
    "outputId": "ea4e4a62-1260-4179-8e41-0450404fe3e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utterance({'id': 's01_e18_c05_u021', 'speaker': Speaker([('id', 'Ross Geller')]), 'conversation_id': 's01_e18_c05_u001', 'reply_to': 's01_e18_c05_u020', 'timestamp': None, 'text': 'Alright.', 'meta': {'tokens': [['Alright', '.']], 'character_entities': [[]], 'emotion': ['Neutral', ['Neutral', 'Neutral', 'Neutral', 'Neutral']], 'caption': None, 'transcript_with_note': None, 'tokens_with_note': None}})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_utterances['s01_e18_c05_u021']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bjb5fkwmN5Ma"
   },
   "source": [
    "## Creating the corpus from a list of utterances\n",
    "\n",
    "We now create the corpus from our dict of utterances. Note, we are are allowing convokit to create conversations IDs automatically after loading the utterances list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0C_xjYMfOKVL"
   },
   "outputs": [],
   "source": [
    "utterance_list = [utt for k, utt in all_utterances.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVyGuspKOU7E"
   },
   "outputs": [],
   "source": [
    "friends_corpus = Corpus(utterances=utterance_list, version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add meta data to automatically generated conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UW5uEDZIcjWO"
   },
   "source": [
    "Sanity checks for the number of conversations in the dataset, the structure of the conversation meta and the first 5 conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oCQcxnu1OZXv",
    "outputId": "d6c78d98-9a75-4f64-a1e0-4ab8634e023b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of conversations in the dataset: 3107/3107\n"
     ]
    }
   ],
   "source": [
    "print(\"number of conversations in the dataset: {}/3107\".format(len(friends_corpus.get_conversation_ids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'season': 's01', 'episode': 'e01', 'scene': 'c01'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_corpus.get_conversation('s01_e01_c01').meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "Uypy9F-Vx0kM",
    "outputId": "7d7dcf7c-40cf-4366-c15d-df2d96397877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample conversation s01_e01_c01:\n",
      "['s01_e01_c01_u001', 's01_e01_c01_u002', 's01_e01_c01_u003', 's01_e01_c01_u004', 's01_e01_c01_u005', 's01_e01_c01_u006', 's01_e01_c01_u007', 's01_e01_c01_u008', 's01_e01_c01_u009', 's01_e01_c01_u010', 's01_e01_c01_u011', 's01_e01_c01_u012', 's01_e01_c01_u013', 's01_e01_c01_u014', 's01_e01_c01_u015', 's01_e01_c01_u016', 's01_e01_c01_u017', 's01_e01_c01_u018', 's01_e01_c01_u019', 's01_e01_c01_u020', 's01_e01_c01_u021', 's01_e01_c01_u022', 's01_e01_c01_u023', 's01_e01_c01_u024', 's01_e01_c01_u025', 's01_e01_c01_u026', 's01_e01_c01_u027', 's01_e01_c01_u028', 's01_e01_c01_u029', 's01_e01_c01_u030', 's01_e01_c01_u031', 's01_e01_c01_u032', 's01_e01_c01_u033', 's01_e01_c01_u034', 's01_e01_c01_u035', 's01_e01_c01_u036', 's01_e01_c01_u037', 's01_e01_c01_u038', 's01_e01_c01_u039', 's01_e01_c01_u040', 's01_e01_c01_u041', 's01_e01_c01_u042', 's01_e01_c01_u043', 's01_e01_c01_u044', 's01_e01_c01_u045', 's01_e01_c01_u046', 's01_e01_c01_u047', 's01_e01_c01_u048', 's01_e01_c01_u049', 's01_e01_c01_u050', 's01_e01_c01_u051', 's01_e01_c01_u052', 's01_e01_c01_u053', 's01_e01_c01_u054', 's01_e01_c01_u055', 's01_e01_c01_u056', 's01_e01_c01_u057', 's01_e01_c01_u058']\n",
      "sample conversation s01_e01_c02:\n",
      "['s01_e01_c02_u001', 's01_e01_c02_u002', 's01_e01_c02_u003', 's01_e01_c02_u004', 's01_e01_c02_u005', 's01_e01_c02_u006', 's01_e01_c02_u007', 's01_e01_c02_u008', 's01_e01_c02_u009', 's01_e01_c02_u010', 's01_e01_c02_u011', 's01_e01_c02_u012', 's01_e01_c02_u013', 's01_e01_c02_u014', 's01_e01_c02_u015', 's01_e01_c02_u016', 's01_e01_c02_u017', 's01_e01_c02_u018', 's01_e01_c02_u019', 's01_e01_c02_u020', 's01_e01_c02_u021', 's01_e01_c02_u022', 's01_e01_c02_u023', 's01_e01_c02_u024', 's01_e01_c02_u025', 's01_e01_c02_u026', 's01_e01_c02_u027', 's01_e01_c02_u028', 's01_e01_c02_u029', 's01_e01_c02_u030', 's01_e01_c02_u031', 's01_e01_c02_u032', 's01_e01_c02_u033', 's01_e01_c02_u034', 's01_e01_c02_u035', 's01_e01_c02_u036', 's01_e01_c02_u037', 's01_e01_c02_u038', 's01_e01_c02_u039', 's01_e01_c02_u040', 's01_e01_c02_u041', 's01_e01_c02_u042', 's01_e01_c02_u043', 's01_e01_c02_u044', 's01_e01_c02_u045', 's01_e01_c02_u046', 's01_e01_c02_u047', 's01_e01_c02_u048', 's01_e01_c02_u049', 's01_e01_c02_u050', 's01_e01_c02_u051', 's01_e01_c02_u052', 's01_e01_c02_u053', 's01_e01_c02_u054', 's01_e01_c02_u055', 's01_e01_c02_u056', 's01_e01_c02_u057', 's01_e01_c02_u058', 's01_e01_c02_u059', 's01_e01_c02_u060', 's01_e01_c02_u061', 's01_e01_c02_u062']\n",
      "sample conversation s01_e01_c03:\n",
      "['s01_e01_c03_u001']\n",
      "sample conversation s01_e01_c04:\n",
      "['s01_e01_c04_u001', 's01_e01_c04_u002', 's01_e01_c04_u003', 's01_e01_c04_u004', 's01_e01_c04_u005', 's01_e01_c04_u006', 's01_e01_c04_u007', 's01_e01_c04_u008', 's01_e01_c04_u009', 's01_e01_c04_u010', 's01_e01_c04_u011', 's01_e01_c04_u012', 's01_e01_c04_u013', 's01_e01_c04_u014', 's01_e01_c04_u015', 's01_e01_c04_u016', 's01_e01_c04_u017', 's01_e01_c04_u018', 's01_e01_c04_u019']\n",
      "sample conversation s01_e01_c05:\n",
      "['s01_e01_c05_u001', 's01_e01_c05_u002', 's01_e01_c05_u003', 's01_e01_c05_u004', 's01_e01_c05_u005', 's01_e01_c05_u006', 's01_e01_c05_u007', 's01_e01_c05_u008', 's01_e01_c05_u009']\n"
     ]
    }
   ],
   "source": [
    "convo_ids = friends_corpus.get_conversation_ids()\n",
    "for i, convo_idx in enumerate(convo_ids[0:5]):\n",
    "    print(\"sample conversation {}:\".format(convo_idx))\n",
    "    print(friends_corpus.get_conversation(convo_idx).get_utterance_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NAHTbGQxcor3"
   },
   "source": [
    "Summary stats for the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "G0pyZSmWW9_1",
    "outputId": "e8e9d98a-c07b-4664-a048-4322ff105c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 700\n",
      "Number of Utterances: 67373\n",
      "Number of Conversations: 3107\n"
     ]
    }
   ],
   "source": [
    "friends_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0WxYF6jbY5l"
   },
   "source": [
    "## Adding corpus-level metadata\n",
    "\n",
    "We add the name of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8oGMAvEza5hL"
   },
   "outputs": [],
   "source": [
    "friends_corpus.meta['name'] = 'Friends Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LiUf8K6hTNjV"
   },
   "source": [
    "# Create the corpus dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaM2QdLJ4kPl"
   },
   "source": [
    "If working in a locally mounted notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtD1v0Jo4nf7"
   },
   "outputs": [],
   "source": [
    "friends_corpus.dump(\"friends-corpus\", base_path = \"/Users/emilytseng/Cornell-Conversational-Analysis-Toolkit/datasets/friends-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uygI-2aU2PKn"
   },
   "source": [
    "If working in Google Colab, first mount your Google Drive, then dump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "aMcBSeS2xumI",
    "outputId": "bb123206-1a9d-47e9-e085-f3c4b8744d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "import google\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1TGJ37nzKUh"
   },
   "outputs": [],
   "source": [
    "friends_corpus.dump(\"friends-corpus\", base_path = \"gdrive/My Drive/F19-CS6742/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aN2CraqRaUYb"
   },
   "outputs": [],
   "source": [
    "with ZipFile(\"gdrive/My Drive/CS6742/friends-corpus.zip\", 'w') as zip_f:\n",
    "  for fname in os.listdir(\"gdrive/My Drive/CS6742/friends-corpus\"):\n",
    "    zip_f.write(\"gdrive/My Drive/CS6742/friends-corpus/\"+fname)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convert-et397.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}