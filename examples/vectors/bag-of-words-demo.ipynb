{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we demonstrate how to:\n",
    "\n",
    "1. Annotate a Corpus's utterances with their bag-of-words vector representations\n",
    "2. Use these bag-of-words vectors in predictive tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an introduction to vectors in ConvoKit, check out this [demo](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/vectors/vector_demo.ipynb) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/subreddit-Cornell\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download('subreddit-Cornell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 7568\n",
      "Number of Utterances: 74467\n",
      "Number of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating the Corpus with bag-of-words vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we use ConvoKit's [Bag-of-words Transformer](https://convokit.cornell.edu/documentation/bow.html) and set it to vectorize the Corpus's utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import BoWTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing default unigram CountVectorizer...Done.\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = BoWTransformer(obj_type=\"utterance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a custom text vectorizer can be sent by configuring the vectorizer parameter:\n",
    "\n",
    "e.g. BoWTransformer(obj_type=\"utterance\", *vectorizer*=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect one of the Corpus utterances to see the changes that get made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before transformation\n",
    "corpus.get_utterance('dsbgljl').vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x122ecc190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bow_vector']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after transformation\n",
    "corpus.get_utterance('dsbgljl').vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Corpus now has a new vector matrix associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bow_vector'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvoKitMatrix('name': bow_vector, 'matrix': <74467x9340 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2108383 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_vector_matrix('bow_vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive task: will an utterance (i.e. Reddit comment) have a positive score?\n",
    "\n",
    "We want to predict whether an utterance will have a positive score (i.e. more upvotes than downvotes) based on its bag-of-words vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting a random utterance, we see that it has a 'score' metadata attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1,\n",
       " 'top_level_comment': 'e3ezz73',\n",
       " 'retrieved_on': 1536963871,\n",
       " 'gilded': 0,\n",
       " 'gildings': None,\n",
       " 'subreddit': 'Cornell',\n",
       " 'stickied': False,\n",
       " 'permalink': '/r/Cornell/comments/93ma7q/prefrosh_stressed_about_housing/e3ezz73/',\n",
       " 'author_flair_text': ''}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.random_utterance().meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use ConvoKit's VectorClassifier to train a classifier model predicting for whether the utterance's score is positive. Notice that the labeller is how we indicate the binary y value that we want the internal model to predict for, while vector_name specifies the vector feature set (i.e. the X data) to use in training the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import VectorClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default classification model (standard scaled logistic regression).\n"
     ]
    }
   ],
   "source": [
    "bow_classifier = VectorClassifier(obj_type=\"utterance\", \n",
    "                                  vector_name='bow_vector',\n",
    "                                  labeller=lambda utt: utt.meta['score'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x122ecc190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fit_transform() step fits the classifier and then uses it to compute predictions for all the \n",
    "# utterances in the Corpus\n",
    "bow_classifier.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dhhm9sa</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw553ml</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dvzmhdx</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dvzpp79</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw0imao</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3bsi2g</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw0mm3b</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5pddzi</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw25pga</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5om61s</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  pred_score\n",
       "id                             \n",
       "dhhm9sa        True         1.0\n",
       "dw553ml        True         1.0\n",
       "dvzmhdx        True         1.0\n",
       "dvzpp79        True         1.0\n",
       "dw0imao        True         1.0\n",
       "c3bsi2g        True         1.0\n",
       "dw0mm3b        True         1.0\n",
       "d5pddzi        True         1.0\n",
       "dw25pga        True         1.0\n",
       "5om61s         True         1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A DataFrame summary of the computed predictions\n",
    "bow_classifier.summarize(corpus).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then inspect the coefficient weights assigned to the bag-of-words n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hotels</th>\n",
       "      <td>1.270001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbhs</th>\n",
       "      <td>1.115690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine</th>\n",
       "      <td>1.109702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>involves</th>\n",
       "      <td>1.081836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lincoln</th>\n",
       "      <td>1.071464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef\n",
       "feat_name          \n",
       "hotels     1.270001\n",
       "hbhs       1.115690\n",
       "engine     1.109702\n",
       "involves   1.081836\n",
       "lincoln    1.071464"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ngrams weighted most positively (i.e. utterances with these ngrams are more likely to have positive scores)\n",
    "bow_classifier.get_coefs(feature_names=corpus.get_vector_matrix('bow_vector').columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mahogany</th>\n",
       "      <td>-0.667785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignoreme</th>\n",
       "      <td>-0.722992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hilton</th>\n",
       "      <td>-0.742234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>-0.764383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation</th>\n",
       "      <td>-0.784593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef\n",
       "feat_name          \n",
       "mahogany  -0.667785\n",
       "ignoreme  -0.722992\n",
       "hilton    -0.742234\n",
       "binary    -0.764383\n",
       "creation  -0.784593"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier.get_coefs(feature_names=bow_transformer.get_vocabulary()).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279546644822538"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The base accuracy by predicting all objects to have the majority label, i.e. has positive score\n",
    "bow_classifier.base_accuracy(corpus)\n",
    "\n",
    "# 92.8% of the corpus utterances already have a positive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491452589737737"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our classifier's accuracy on the Corpus\n",
    "bow_classifier.accuracy(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.34      0.49      5365\n",
      "        True       0.95      1.00      0.97     69102\n",
      "\n",
      "    accuracy                           0.95     74467\n",
      "   macro avg       0.91      0.67      0.73     74467\n",
      "weighted avg       0.95      0.95      0.94     74467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bow_classifier.classification_report(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words prediction for Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as utterances have bag-of-words vectors, we might imagine Conversations and Speakers having bag-of-words vectors as well, where:\n",
    "- The text of a Conversation is the *combined* texts of all the Utterances within it\n",
    "- The text of a Speaker is the *combined* texts of all the Utterances made by the Speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoWTransformer provides native support for such vectorizations. In this example, we predict for whether a Conversation will eventually double in length or stay the same based on the bag-of-words representations of the first five utterances in the Conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As r/Cornell's Conversations begin with the thread post (instead of only comments in the thread), we reindex the Conversations to begin with the top-level comments in each thread. This is a necessary step as our focus is on whether or not a **comment thread** will double in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_comment_ids = [utt.id for utt in corpus.iter_utterances() if utt.id == utt.meta['top_level_comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 7568\n",
      "Number of Utterances: 74467\n",
      "Number of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32893"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_level_comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mWARNING: \u001b[0mConversation pcww4 reply-to chain does not form a valid tree.\n",
      "\u001b[91mWARNING: \u001b[0mConversation pegd2 reply-to chain does not form a valid tree.\n",
      "\u001b[91mWARNING: \u001b[0mFailed to find some of the specified new convo roots:\n",
      "\n",
      "['c3od15i', 'c3p1rn8', 'c3ocsyl', 'c3oyf4d', 'c3p8bze']\n"
     ]
    }
   ],
   "source": [
    "threads_corpus = corpus.reindex_conversations(new_convo_roots=top_level_comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 6160\n",
      "Number of Utterances: 63697\n",
      "Number of Conversations: 32888\n"
     ]
    }
   ],
   "source": [
    "threads_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label annotation for whether the thread doubles in length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thread in threads_corpus.iter_conversations():\n",
    "    thread_len = len(list(thread.iter_utterances()))\n",
    "    if thread_len == 5:\n",
    "        thread.meta['thread_doubles'] = False\n",
    "    elif thread_len >= 10:\n",
    "        thread.meta['thread_doubles'] = True\n",
    "    else:\n",
    "        thread.meta['thread_doubles'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW annotation of first 5 utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing default unigram CountVectorizer...Done.\n"
     ]
    }
   ],
   "source": [
    "# We set our BoWTransformer to use only the first 5 utterances in the Conversation by configuring 'text_func'\n",
    "bow_transformer2 = BoWTransformer(obj_type=\"conversation\", vector_name='bow_vector_2',\n",
    "                text_func=lambda convo: ' '.join([utt.text for utt in convo.get_chronological_utterance_list()[:5]])\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x125ef4c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer2.fit_transform(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bow_vector_2'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads_corpus.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default classification model (standard scaled logistic regression).\n"
     ]
    }
   ],
   "source": [
    "bow_classifier2 = VectorClassifier(obj_type=\"conversation\", vector_name='bow_vector_2',\n",
    "                                   labeller=lambda convo: convo.meta['thread_doubles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x125ef4c10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.fit_transform(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = bow_classifier2.summarize(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt05qyf</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dandio0</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwa6k96</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsldpxg</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e70wjy3</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  pred_score\n",
       "id                             \n",
       "dt05qyf        True         1.0\n",
       "dandio0        True         1.0\n",
       "dwa6k96        True         1.0\n",
       "dsldpxg        True         1.0\n",
       "e70wjy3        True         1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drduxx1</th>\n",
       "      <td>False</td>\n",
       "      <td>2.465251e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dl7q7n2</th>\n",
       "      <td>False</td>\n",
       "      <td>8.144366e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxfib8r</th>\n",
       "      <td>False</td>\n",
       "      <td>2.709070e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwqaa06</th>\n",
       "      <td>False</td>\n",
       "      <td>2.682305e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8y9akn</th>\n",
       "      <td>False</td>\n",
       "      <td>1.646025e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction    pred_score\n",
       "id                               \n",
       "drduxx1       False  2.465251e-12\n",
       "dl7q7n2       False  8.144366e-14\n",
       "dxfib8r       False  2.709070e-15\n",
       "dwqaa06       False  2.682305e-16\n",
       "d8y9akn       False  1.646025e-16"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6761904761904762"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.base_accuracy(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992063492063492"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.accuracy(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       852\n",
      "        True       1.00      1.00      1.00       408\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bow_classifier2.classification_report(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this artificial setup, our Bag-of-words classifier has achieved very high accuracy because the test and train data are identical. In a proper train-test split setting, our classifier would perform much more poorly. Setting up such a train-test evaluation is straightforward as well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only conversations that have at least 5 utterances, i.e. from earlier,\n",
    "# this is any conversation that has thread_doubles with a value that is not None.\n",
    "valid_convos = list(threads_corpus.iter_conversations(lambda convo: convo.meta['thread_doubles'] is not None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 6160\n",
      "Number of Utterances: 63697\n",
      "Number of Conversations: 32888\n"
     ]
    }
   ],
   "source": [
    "threads_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_convos, test_convos = train_test_split(valid_convos, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008 252\n"
     ]
    }
   ],
   "source": [
    "print(len(train_convos), len(test_convos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in train_convos:\n",
    "    convo.meta['train_test_type'] = 'train'\n",
    "    \n",
    "for convo in test_convos:\n",
    "    convo.meta['train_test_type'] = 'test'\n",
    "\n",
    "# any other convo not part of the train/test split should have the metadata attribute value set to None\n",
    "for convo in threads_corpus.iter_conversations():\n",
    "    if 'train_test_type' not in convo.meta:\n",
    "        convo.meta['train_test_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.classifier.vector_classifier.VectorClassifier at 0x12766a610>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier only on train data\n",
    "bow_classifier2.fit(threads_corpus, selector=lambda convo: convo.meta['train_test_type'] == 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>czqe3vw</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999904e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crd2smi</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999885e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3fkgch</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999674e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dyg6ymm</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999420e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dn4rvuv</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999407e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxa82rx</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999283e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dm02kj3</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999026e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e564q25</th>\n",
       "      <td>True</td>\n",
       "      <td>9.998198e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drzdhb4</th>\n",
       "      <td>True</td>\n",
       "      <td>9.997067e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drzo1ex</th>\n",
       "      <td>True</td>\n",
       "      <td>9.996849e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da483rs</th>\n",
       "      <td>True</td>\n",
       "      <td>9.995258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>djfl3f0</th>\n",
       "      <td>True</td>\n",
       "      <td>9.990694e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dgwtce1</th>\n",
       "      <td>True</td>\n",
       "      <td>9.984255e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnug9fy</th>\n",
       "      <td>True</td>\n",
       "      <td>9.975925e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds7890c</th>\n",
       "      <td>True</td>\n",
       "      <td>9.975021e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detk4cl</th>\n",
       "      <td>True</td>\n",
       "      <td>9.964009e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doy1akd</th>\n",
       "      <td>True</td>\n",
       "      <td>9.957056e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg44ad</th>\n",
       "      <td>True</td>\n",
       "      <td>9.955436e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dgcxnhr</th>\n",
       "      <td>True</td>\n",
       "      <td>9.932621e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cj8reit</th>\n",
       "      <td>True</td>\n",
       "      <td>9.924327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dssjgkm</th>\n",
       "      <td>True</td>\n",
       "      <td>9.919800e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cvxzsbp</th>\n",
       "      <td>True</td>\n",
       "      <td>9.918168e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cx8ch2x</th>\n",
       "      <td>True</td>\n",
       "      <td>9.906757e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drqai86</th>\n",
       "      <td>True</td>\n",
       "      <td>9.827284e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dgksrll</th>\n",
       "      <td>True</td>\n",
       "      <td>9.824816e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e86dai3</th>\n",
       "      <td>True</td>\n",
       "      <td>9.801660e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnh39vh</th>\n",
       "      <td>True</td>\n",
       "      <td>9.738843e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9x3hio</th>\n",
       "      <td>True</td>\n",
       "      <td>9.694669e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dqi8dmr</th>\n",
       "      <td>True</td>\n",
       "      <td>9.558338e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e4bejst</th>\n",
       "      <td>True</td>\n",
       "      <td>9.433509e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cwevugo</th>\n",
       "      <td>False</td>\n",
       "      <td>4.131380e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcsq3lu</th>\n",
       "      <td>False</td>\n",
       "      <td>3.782295e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1mdhs1</th>\n",
       "      <td>False</td>\n",
       "      <td>3.686571e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcsz5it</th>\n",
       "      <td>False</td>\n",
       "      <td>3.668125e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e6bhemk</th>\n",
       "      <td>False</td>\n",
       "      <td>3.120269e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e4vjxfd</th>\n",
       "      <td>False</td>\n",
       "      <td>1.654403e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>djxk078</th>\n",
       "      <td>False</td>\n",
       "      <td>1.176553e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e8ri422</th>\n",
       "      <td>False</td>\n",
       "      <td>9.054698e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drduxx1</th>\n",
       "      <td>False</td>\n",
       "      <td>7.631640e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e0qv7gw</th>\n",
       "      <td>False</td>\n",
       "      <td>4.845366e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cqva9en</th>\n",
       "      <td>False</td>\n",
       "      <td>3.851620e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do9uy0q</th>\n",
       "      <td>False</td>\n",
       "      <td>2.315198e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6awpnf</th>\n",
       "      <td>False</td>\n",
       "      <td>1.473615e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2ojyq5</th>\n",
       "      <td>False</td>\n",
       "      <td>1.243440e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>djq66qe</th>\n",
       "      <td>False</td>\n",
       "      <td>1.065258e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c5kqr3q</th>\n",
       "      <td>False</td>\n",
       "      <td>8.775798e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cw401k4</th>\n",
       "      <td>False</td>\n",
       "      <td>8.638773e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d77mbr5</th>\n",
       "      <td>False</td>\n",
       "      <td>5.995873e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ckif2vo</th>\n",
       "      <td>False</td>\n",
       "      <td>3.032161e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwk291x</th>\n",
       "      <td>False</td>\n",
       "      <td>9.325407e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtxmu1w</th>\n",
       "      <td>False</td>\n",
       "      <td>8.599597e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9v43ap</th>\n",
       "      <td>False</td>\n",
       "      <td>5.551958e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e447bx1</th>\n",
       "      <td>False</td>\n",
       "      <td>7.998432e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e6m7j9z</th>\n",
       "      <td>False</td>\n",
       "      <td>3.367153e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c4drajn</th>\n",
       "      <td>False</td>\n",
       "      <td>2.165973e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dqvzh5c</th>\n",
       "      <td>False</td>\n",
       "      <td>7.252564e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dujg8i8</th>\n",
       "      <td>False</td>\n",
       "      <td>4.172389e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxfib8r</th>\n",
       "      <td>False</td>\n",
       "      <td>2.440114e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwqaa06</th>\n",
       "      <td>False</td>\n",
       "      <td>6.994512e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c36emq6</th>\n",
       "      <td>False</td>\n",
       "      <td>9.594109e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction    pred_score\n",
       "id                               \n",
       "czqe3vw        True  9.999904e-01\n",
       "crd2smi        True  9.999885e-01\n",
       "c3fkgch        True  9.999674e-01\n",
       "dyg6ymm        True  9.999420e-01\n",
       "dn4rvuv        True  9.999407e-01\n",
       "dxa82rx        True  9.999283e-01\n",
       "dm02kj3        True  9.999026e-01\n",
       "e564q25        True  9.998198e-01\n",
       "drzdhb4        True  9.997067e-01\n",
       "drzo1ex        True  9.996849e-01\n",
       "da483rs        True  9.995258e-01\n",
       "djfl3f0        True  9.990694e-01\n",
       "dgwtce1        True  9.984255e-01\n",
       "dnug9fy        True  9.975925e-01\n",
       "ds7890c        True  9.975021e-01\n",
       "detk4cl        True  9.964009e-01\n",
       "doy1akd        True  9.957056e-01\n",
       "deg44ad        True  9.955436e-01\n",
       "dgcxnhr        True  9.932621e-01\n",
       "cj8reit        True  9.924327e-01\n",
       "dssjgkm        True  9.919800e-01\n",
       "cvxzsbp        True  9.918168e-01\n",
       "cx8ch2x        True  9.906757e-01\n",
       "drqai86        True  9.827284e-01\n",
       "dgksrll        True  9.824816e-01\n",
       "e86dai3        True  9.801660e-01\n",
       "dnh39vh        True  9.738843e-01\n",
       "c9x3hio        True  9.694669e-01\n",
       "dqi8dmr        True  9.558338e-01\n",
       "e4bejst        True  9.433509e-01\n",
       "...             ...           ...\n",
       "cwevugo       False  4.131380e-05\n",
       "dcsq3lu       False  3.782295e-05\n",
       "d1mdhs1       False  3.686571e-05\n",
       "dcsz5it       False  3.668125e-05\n",
       "e6bhemk       False  3.120269e-05\n",
       "e4vjxfd       False  1.654403e-05\n",
       "djxk078       False  1.176553e-05\n",
       "e8ri422       False  9.054698e-06\n",
       "drduxx1       False  7.631640e-06\n",
       "e0qv7gw       False  4.845366e-06\n",
       "cqva9en       False  3.851620e-06\n",
       "do9uy0q       False  2.315198e-06\n",
       "d6awpnf       False  1.473615e-06\n",
       "d2ojyq5       False  1.243440e-06\n",
       "djq66qe       False  1.065258e-06\n",
       "c5kqr3q       False  8.775798e-07\n",
       "cw401k4       False  8.638773e-07\n",
       "d77mbr5       False  5.995873e-07\n",
       "ckif2vo       False  3.032161e-07\n",
       "dwk291x       False  9.325407e-08\n",
       "dtxmu1w       False  8.599597e-08\n",
       "c9v43ap       False  5.551958e-09\n",
       "e447bx1       False  7.998432e-10\n",
       "e6m7j9z       False  3.367153e-10\n",
       "c4drajn       False  2.165973e-10\n",
       "dqvzh5c       False  7.252564e-11\n",
       "dujg8i8       False  4.172389e-12\n",
       "dxfib8r       False  2.440114e-12\n",
       "dwqaa06       False  6.994512e-17\n",
       "c36emq6       False  9.594109e-22\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classifier on test data\n",
    "\n",
    "# First annotate the conversation with the prediction\n",
    "bow_classifier2.transform(threads_corpus, selector=lambda convo: convo.meta['train_test_type'] == 'test')\n",
    "\n",
    "# Then evaluate the accuracy of this prediction\n",
    "bow_classifier2.summarize(threads_corpus, selector=lambda convo: convo.meta['train_test_type'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.78      0.77       175\n",
      "        True       0.47      0.44      0.46        77\n",
      "\n",
      "    accuracy                           0.68       252\n",
      "   macro avg       0.62      0.61      0.61       252\n",
      "weighted avg       0.67      0.68      0.68       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bow_classifier2.classification_report(threads_corpus, \n",
    "                                            selector=lambda convo: convo.meta['train_test_type'] == 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a cross-validated evaluation...Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.63888889, 0.59920635, 0.64285714, 0.65079365, 0.5952381 ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.evaluate_with_cv(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a train-test-split evaluation...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.626984126984127, array([[126,  40],\n",
       "        [ 54,  32]]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.evaluate_with_train_test_split(threads_corpus, \n",
    "                                               selector=lambda convo: convo.meta['thread_doubles'] is not None,\n",
    "                                               test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the demo. Check out [our other demo on predicting comment-growth and commenter-growth](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/hyperconvo/predictive_tasks.ipynb) to see how bag-of-words vectors can be used in a paired predictive setting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
